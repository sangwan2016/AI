{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"딥러닝모델-코나3.ipynb","provenance":[],"authorship_tag":"ABX9TyNKQ9+rSDTkvasGwIzfVN8R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iEWVnNSKH89n"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","source":["!git clone https://github.com/taehojo/data.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-UgopMu4IE8h","executionInfo":{"status":"ok","timestamp":1659503692238,"user_tz":-540,"elapsed":708,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"outputId":"0fd36e7c-9474-4312-f67a-589b9ecb6f92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'data'...\n","remote: Enumerating objects: 21, done.\u001b[K\n","remote: Counting objects: 100% (21/21), done.\u001b[K\n","remote: Compressing objects: 100% (18/18), done.\u001b[K\n","remote: Total 21 (delta 3), reused 20 (delta 2), pack-reused 0\u001b[K\n","Unpacking objects: 100% (21/21), done.\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('./data/powerconsumption.csv', header = None)"],"metadata":{"id":"qV6nFtRVINgn","executionInfo":{"status":"error","timestamp":1659515080891,"user_tz":-540,"elapsed":300,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"colab":{"base_uri":"https://localhost:8080/","height":233},"outputId":"bbcf6932-61bc-4e51-8b41-885b793e127a"},"execution_count":37,"outputs":[{"output_type":"error","ename":"ParserError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-0b2641e329c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/powerconsumption.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 9 fields in line 12731, saw 11\n"]}]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"_Tsbv8HpIVzk","executionInfo":{"status":"ok","timestamp":1659503735056,"user_tz":-540,"elapsed":282,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"outputId":"c276f2b1-e582-49ee-d4d0-78303e0734f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0       1       2       3       4       5       6       7       8   \\\n","0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n","1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n","2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n","3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n","4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n","\n","       9   ...      51      52      53      54      55      56      57  \\\n","0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n","1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n","2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n","3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n","4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n","\n","       58      59  60  \n","0  0.0090  0.0032   0  \n","1  0.0052  0.0044   0  \n","2  0.0095  0.0078   0  \n","3  0.0040  0.0117   0  \n","4  0.0107  0.0094   0  \n","\n","[5 rows x 61 columns]"],"text/html":["\n","  <div id=\"df-2edd60c7-4ceb-4d44-bcf1-e4e83ff2e37c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0200</td>\n","      <td>0.0371</td>\n","      <td>0.0428</td>\n","      <td>0.0207</td>\n","      <td>0.0954</td>\n","      <td>0.0986</td>\n","      <td>0.1539</td>\n","      <td>0.1601</td>\n","      <td>0.3109</td>\n","      <td>0.2111</td>\n","      <td>...</td>\n","      <td>0.0027</td>\n","      <td>0.0065</td>\n","      <td>0.0159</td>\n","      <td>0.0072</td>\n","      <td>0.0167</td>\n","      <td>0.0180</td>\n","      <td>0.0084</td>\n","      <td>0.0090</td>\n","      <td>0.0032</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0453</td>\n","      <td>0.0523</td>\n","      <td>0.0843</td>\n","      <td>0.0689</td>\n","      <td>0.1183</td>\n","      <td>0.2583</td>\n","      <td>0.2156</td>\n","      <td>0.3481</td>\n","      <td>0.3337</td>\n","      <td>0.2872</td>\n","      <td>...</td>\n","      <td>0.0084</td>\n","      <td>0.0089</td>\n","      <td>0.0048</td>\n","      <td>0.0094</td>\n","      <td>0.0191</td>\n","      <td>0.0140</td>\n","      <td>0.0049</td>\n","      <td>0.0052</td>\n","      <td>0.0044</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0262</td>\n","      <td>0.0582</td>\n","      <td>0.1099</td>\n","      <td>0.1083</td>\n","      <td>0.0974</td>\n","      <td>0.2280</td>\n","      <td>0.2431</td>\n","      <td>0.3771</td>\n","      <td>0.5598</td>\n","      <td>0.6194</td>\n","      <td>...</td>\n","      <td>0.0232</td>\n","      <td>0.0166</td>\n","      <td>0.0095</td>\n","      <td>0.0180</td>\n","      <td>0.0244</td>\n","      <td>0.0316</td>\n","      <td>0.0164</td>\n","      <td>0.0095</td>\n","      <td>0.0078</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0100</td>\n","      <td>0.0171</td>\n","      <td>0.0623</td>\n","      <td>0.0205</td>\n","      <td>0.0205</td>\n","      <td>0.0368</td>\n","      <td>0.1098</td>\n","      <td>0.1276</td>\n","      <td>0.0598</td>\n","      <td>0.1264</td>\n","      <td>...</td>\n","      <td>0.0121</td>\n","      <td>0.0036</td>\n","      <td>0.0150</td>\n","      <td>0.0085</td>\n","      <td>0.0073</td>\n","      <td>0.0050</td>\n","      <td>0.0044</td>\n","      <td>0.0040</td>\n","      <td>0.0117</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0762</td>\n","      <td>0.0666</td>\n","      <td>0.0481</td>\n","      <td>0.0394</td>\n","      <td>0.0590</td>\n","      <td>0.0649</td>\n","      <td>0.1209</td>\n","      <td>0.2467</td>\n","      <td>0.3564</td>\n","      <td>0.4459</td>\n","      <td>...</td>\n","      <td>0.0031</td>\n","      <td>0.0054</td>\n","      <td>0.0105</td>\n","      <td>0.0110</td>\n","      <td>0.0015</td>\n","      <td>0.0072</td>\n","      <td>0.0048</td>\n","      <td>0.0107</td>\n","      <td>0.0094</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 61 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2edd60c7-4ceb-4d44-bcf1-e4e83ff2e37c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2edd60c7-4ceb-4d44-bcf1-e4e83ff2e37c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2edd60c7-4ceb-4d44-bcf1-e4e83ff2e37c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df[60].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cyWCahmIYoV","executionInfo":{"status":"ok","timestamp":1659503765223,"user_tz":-540,"elapsed":252,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"outputId":"21df6dc2-da3d-4d64-f3ac-6fdc76f1883a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    111\n","0     97\n","Name: 60, dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["X = df.iloc[:,0:60]\n","y = df.iloc[:,60]"],"metadata":{"id":"K_Wt-hvpIh8c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense"],"metadata":{"id":"jQsp5pibIpDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Dense(24, input_dim = 60, activation = 'relu'))\n","model.add(Dense(10, activation = 'relu'))\n","model.add(Dense(1, activation = 'sigmoid'))"],"metadata":{"id":"JP-pl2tpIzoN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics =['accuracy'])\n","history = model.fit(X,y, epochs = 200, batch_size = 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RGGXiLitJHyE","executionInfo":{"status":"ok","timestamp":1659504028181,"user_tz":-540,"elapsed":22011,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"outputId":"67324778-6fcd-4d13-808d-ba132e45b305"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","21/21 [==============================] - 1s 3ms/step - loss: 0.7385 - accuracy: 0.4615\n","Epoch 2/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.6250\n","Epoch 3/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.5962\n","Epoch 4/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6538\n","Epoch 5/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6731\n","Epoch 6/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6827\n","Epoch 7/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7067\n","Epoch 8/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.7163\n","Epoch 9/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7260\n","Epoch 10/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7740\n","Epoch 11/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7548\n","Epoch 12/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7356\n","Epoch 13/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7692\n","Epoch 14/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7788\n","Epoch 15/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7740\n","Epoch 16/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7837\n","Epoch 17/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.8029\n","Epoch 18/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7740\n","Epoch 19/200\n","21/21 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7885\n","Epoch 20/200\n","21/21 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8077\n","Epoch 21/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8077\n","Epoch 22/200\n","21/21 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7981\n","Epoch 23/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.7933\n","Epoch 24/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8269\n","Epoch 25/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7885\n","Epoch 26/200\n","21/21 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8365\n","Epoch 27/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8317\n","Epoch 28/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8317\n","Epoch 29/200\n","21/21 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8269\n","Epoch 30/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8317\n","Epoch 31/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8413\n","Epoch 32/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.8365\n","Epoch 33/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8606\n","Epoch 34/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8750\n","Epoch 35/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8365\n","Epoch 36/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8365\n","Epoch 37/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8558\n","Epoch 38/200\n","21/21 [==============================] - 0s 6ms/step - loss: 0.3373 - accuracy: 0.8558\n","Epoch 39/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8750\n","Epoch 40/200\n","21/21 [==============================] - 0s 6ms/step - loss: 0.3408 - accuracy: 0.8462\n","Epoch 41/200\n","21/21 [==============================] - 0s 6ms/step - loss: 0.3349 - accuracy: 0.8702\n","Epoch 42/200\n","21/21 [==============================] - 0s 7ms/step - loss: 0.3179 - accuracy: 0.8798\n","Epoch 43/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8798\n","Epoch 44/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.8894\n","Epoch 45/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8702\n","Epoch 46/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8894\n","Epoch 47/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8942\n","Epoch 48/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8750\n","Epoch 49/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8654\n","Epoch 50/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8750\n","Epoch 51/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.8846\n","Epoch 52/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8894\n","Epoch 53/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8846\n","Epoch 54/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.8798\n","Epoch 55/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8942\n","Epoch 56/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.9087\n","Epoch 57/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.9087\n","Epoch 58/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.8990\n","Epoch 59/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9087\n","Epoch 60/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8846\n","Epoch 61/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.8990\n","Epoch 62/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9135\n","Epoch 63/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.9183\n","Epoch 64/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2397 - accuracy: 0.9183\n","Epoch 65/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.9087\n","Epoch 66/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9135\n","Epoch 67/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9231\n","Epoch 68/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.2327 - accuracy: 0.9183\n","Epoch 69/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9135\n","Epoch 70/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9231\n","Epoch 71/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.9231\n","Epoch 72/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.2211 - accuracy: 0.9327\n","Epoch 73/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.9231\n","Epoch 74/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9375\n","Epoch 75/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9327\n","Epoch 76/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.2061 - accuracy: 0.9327\n","Epoch 77/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9375\n","Epoch 78/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9423\n","Epoch 79/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9231\n","Epoch 80/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9375\n","Epoch 81/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9375\n","Epoch 82/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9327\n","Epoch 83/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9327\n","Epoch 84/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9327\n","Epoch 85/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9471\n","Epoch 86/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9279\n","Epoch 87/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9423\n","Epoch 88/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9519\n","Epoch 89/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9471\n","Epoch 90/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9423\n","Epoch 91/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9471\n","Epoch 92/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.9375\n","Epoch 93/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9567\n","Epoch 94/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9423\n","Epoch 95/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9567\n","Epoch 96/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.9423\n","Epoch 97/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9519\n","Epoch 98/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9567\n","Epoch 99/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9519\n","Epoch 100/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9615\n","Epoch 101/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9519\n","Epoch 102/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9567\n","Epoch 103/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9663\n","Epoch 104/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9615\n","Epoch 105/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9663\n","Epoch 106/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9567\n","Epoch 107/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9712\n","Epoch 108/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9615\n","Epoch 109/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9615\n","Epoch 110/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9615\n","Epoch 111/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9712\n","Epoch 112/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9663\n","Epoch 113/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9615\n","Epoch 114/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9663\n","Epoch 115/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9663\n","Epoch 116/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9856\n","Epoch 117/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 0.9712\n","Epoch 118/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9712\n","Epoch 119/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9808\n","Epoch 120/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9856\n","Epoch 121/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9712\n","Epoch 122/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9760\n","Epoch 123/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9760\n","Epoch 124/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9712\n","Epoch 125/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9760\n","Epoch 126/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9808\n","Epoch 127/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9808\n","Epoch 128/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9856\n","Epoch 129/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9760\n","Epoch 130/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9712\n","Epoch 131/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9760\n","Epoch 132/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9808\n","Epoch 133/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9856\n","Epoch 134/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9712\n","Epoch 135/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9904\n","Epoch 136/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9808\n","Epoch 137/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9904\n","Epoch 138/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9856\n","Epoch 139/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9856\n","Epoch 140/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9856\n","Epoch 141/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9904\n","Epoch 142/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9856\n","Epoch 143/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9904\n","Epoch 144/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9856\n","Epoch 145/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9808\n","Epoch 146/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9856\n","Epoch 147/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9904\n","Epoch 148/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9904\n","Epoch 149/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9856\n","Epoch 150/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9856\n","Epoch 151/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9856\n","Epoch 152/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9904\n","Epoch 153/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9904\n","Epoch 154/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9808\n","Epoch 155/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9808\n","Epoch 156/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9952\n","Epoch 157/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9904\n","Epoch 158/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9904\n","Epoch 159/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9856\n","Epoch 160/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9856\n","Epoch 161/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9856\n","Epoch 162/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9904\n","Epoch 163/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9808\n","Epoch 164/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9856\n","Epoch 165/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9952\n","Epoch 166/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9904\n","Epoch 167/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9904\n","Epoch 168/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9904\n","Epoch 169/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9856\n","Epoch 170/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9904\n","Epoch 171/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9904\n","Epoch 172/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9904\n","Epoch 173/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9904\n","Epoch 174/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9952\n","Epoch 175/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9904\n","Epoch 176/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9904\n","Epoch 177/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9952\n","Epoch 178/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9904\n","Epoch 179/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9904\n","Epoch 180/200\n","21/21 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9856\n","Epoch 181/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9904\n","Epoch 182/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9856\n","Epoch 183/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9952\n","Epoch 184/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9904\n","Epoch 185/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9952\n","Epoch 186/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9952\n","Epoch 187/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9952\n","Epoch 188/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9904\n","Epoch 189/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9952\n","Epoch 190/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9952\n","Epoch 191/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9952\n","Epoch 192/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9904\n","Epoch 193/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9952\n","Epoch 194/200\n","21/21 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9952\n","Epoch 195/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9904\n","Epoch 196/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9952\n","Epoch 197/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9952\n","Epoch 198/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9952\n","Epoch 199/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9952\n","Epoch 200/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9952\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"DL17aAW2LAsI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, shuffle = True)"],"metadata":{"id":"XAGFDO5ULRZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(X_train, y_train, epochs = 200, batch_size = 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzXoEu_GMByl","executionInfo":{"status":"ok","timestamp":1659504753507,"user_tz":-540,"elapsed":28319,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"outputId":"636cd955-f8d1-4251-e6d8-0bea36ed7792"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","29/29 [==============================] - 1s 5ms/step - loss: 0.0348 - accuracy: 0.9931\n","Epoch 2/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9931\n","Epoch 3/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9862\n","Epoch 4/200\n","29/29 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9931\n","Epoch 5/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9931\n","Epoch 6/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9931\n","Epoch 7/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9931\n","Epoch 8/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9931\n","Epoch 9/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9931\n","Epoch 10/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9931\n","Epoch 11/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 1.0000\n","Epoch 12/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 1.0000\n","Epoch 13/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000\n","Epoch 14/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 1.0000\n","Epoch 15/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 1.0000\n","Epoch 16/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 1.0000\n","Epoch 17/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000\n","Epoch 18/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000\n","Epoch 19/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 1.0000\n","Epoch 20/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 1.0000\n","Epoch 21/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 1.0000\n","Epoch 22/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 1.0000\n","Epoch 23/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000\n","Epoch 24/200\n","29/29 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 1.0000\n","Epoch 25/200\n","29/29 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 1.0000\n","Epoch 26/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 1.0000\n","Epoch 27/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 1.0000\n","Epoch 28/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 1.0000\n","Epoch 29/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000\n","Epoch 30/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000\n","Epoch 31/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n","Epoch 32/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000\n","Epoch 33/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n","Epoch 34/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n","Epoch 35/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000\n","Epoch 36/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000\n","Epoch 37/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n","Epoch 38/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n","Epoch 39/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n","Epoch 40/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 41/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 42/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n","Epoch 43/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000\n","Epoch 44/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n","Epoch 45/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 46/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000\n","Epoch 47/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 48/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 49/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000\n","Epoch 50/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 51/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 52/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 53/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 54/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 55/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n","Epoch 56/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n","Epoch 57/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000\n","Epoch 58/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000\n","Epoch 59/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 60/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 61/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 62/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 63/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n","Epoch 64/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 65/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 66/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 67/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 68/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 69/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 70/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 71/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 72/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 73/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 74/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 75/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 76/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 77/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 78/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 79/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 80/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 81/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 82/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 83/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 84/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 85/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 86/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 87/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 88/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 89/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 90/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 91/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 92/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 93/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 94/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 95/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 96/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 97/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 98/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 99/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 100/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 101/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 102/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 103/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 104/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 105/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 106/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 107/200\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 108/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 109/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 110/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 111/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 112/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 113/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 114/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 115/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 116/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 117/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 118/200\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 119/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 120/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 121/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 122/200\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 123/200\n","29/29 [==============================] - 0s 4ms/step - loss: 9.0636e-04 - accuracy: 1.0000\n","Epoch 124/200\n","29/29 [==============================] - 0s 3ms/step - loss: 9.5216e-04 - accuracy: 1.0000\n","Epoch 125/200\n","29/29 [==============================] - 0s 4ms/step - loss: 8.6876e-04 - accuracy: 1.0000\n","Epoch 126/200\n","29/29 [==============================] - 0s 3ms/step - loss: 9.2772e-04 - accuracy: 1.0000\n","Epoch 127/200\n","29/29 [==============================] - 0s 4ms/step - loss: 8.9151e-04 - accuracy: 1.0000\n","Epoch 128/200\n","29/29 [==============================] - 0s 4ms/step - loss: 8.6489e-04 - accuracy: 1.0000\n","Epoch 129/200\n","29/29 [==============================] - 0s 4ms/step - loss: 8.7385e-04 - accuracy: 1.0000\n","Epoch 130/200\n","29/29 [==============================] - 0s 4ms/step - loss: 8.1231e-04 - accuracy: 1.0000\n","Epoch 131/200\n","29/29 [==============================] - 0s 5ms/step - loss: 8.1755e-04 - accuracy: 1.0000\n","Epoch 132/200\n","29/29 [==============================] - 0s 4ms/step - loss: 7.9257e-04 - accuracy: 1.0000\n","Epoch 133/200\n","29/29 [==============================] - 0s 4ms/step - loss: 8.1723e-04 - accuracy: 1.0000\n","Epoch 134/200\n","29/29 [==============================] - 0s 4ms/step - loss: 7.9228e-04 - accuracy: 1.0000\n","Epoch 135/200\n","29/29 [==============================] - 0s 4ms/step - loss: 7.4603e-04 - accuracy: 1.0000\n","Epoch 136/200\n","29/29 [==============================] - 0s 5ms/step - loss: 7.2407e-04 - accuracy: 1.0000\n","Epoch 137/200\n","29/29 [==============================] - 0s 4ms/step - loss: 7.0356e-04 - accuracy: 1.0000\n","Epoch 138/200\n","29/29 [==============================] - 0s 4ms/step - loss: 8.3160e-04 - accuracy: 1.0000\n","Epoch 139/200\n","29/29 [==============================] - 0s 3ms/step - loss: 7.3923e-04 - accuracy: 1.0000\n","Epoch 140/200\n","29/29 [==============================] - 0s 3ms/step - loss: 6.7796e-04 - accuracy: 1.0000\n","Epoch 141/200\n","29/29 [==============================] - 0s 4ms/step - loss: 6.8233e-04 - accuracy: 1.0000\n","Epoch 142/200\n","29/29 [==============================] - 0s 3ms/step - loss: 7.8583e-04 - accuracy: 1.0000\n","Epoch 143/200\n","29/29 [==============================] - 0s 4ms/step - loss: 7.0596e-04 - accuracy: 1.0000\n","Epoch 144/200\n","29/29 [==============================] - 0s 3ms/step - loss: 6.5261e-04 - accuracy: 1.0000\n","Epoch 145/200\n","29/29 [==============================] - 0s 4ms/step - loss: 6.1551e-04 - accuracy: 1.0000\n","Epoch 146/200\n","29/29 [==============================] - 0s 4ms/step - loss: 6.0907e-04 - accuracy: 1.0000\n","Epoch 147/200\n","29/29 [==============================] - 0s 4ms/step - loss: 6.0090e-04 - accuracy: 1.0000\n","Epoch 148/200\n","29/29 [==============================] - 0s 3ms/step - loss: 5.9335e-04 - accuracy: 1.0000\n","Epoch 149/200\n","29/29 [==============================] - 0s 3ms/step - loss: 5.7252e-04 - accuracy: 1.0000\n","Epoch 150/200\n","29/29 [==============================] - 0s 4ms/step - loss: 5.5480e-04 - accuracy: 1.0000\n","Epoch 151/200\n","29/29 [==============================] - 0s 3ms/step - loss: 5.5210e-04 - accuracy: 1.0000\n","Epoch 152/200\n","29/29 [==============================] - 0s 3ms/step - loss: 6.4159e-04 - accuracy: 1.0000\n","Epoch 153/200\n","29/29 [==============================] - 0s 3ms/step - loss: 6.3271e-04 - accuracy: 1.0000\n","Epoch 154/200\n","29/29 [==============================] - 0s 4ms/step - loss: 5.6765e-04 - accuracy: 1.0000\n","Epoch 155/200\n","29/29 [==============================] - 0s 4ms/step - loss: 5.2570e-04 - accuracy: 1.0000\n","Epoch 156/200\n","29/29 [==============================] - 0s 4ms/step - loss: 5.4086e-04 - accuracy: 1.0000\n","Epoch 157/200\n","29/29 [==============================] - 0s 4ms/step - loss: 5.1223e-04 - accuracy: 1.0000\n","Epoch 158/200\n","29/29 [==============================] - 0s 4ms/step - loss: 4.8588e-04 - accuracy: 1.0000\n","Epoch 159/200\n","29/29 [==============================] - 0s 5ms/step - loss: 5.5219e-04 - accuracy: 1.0000\n","Epoch 160/200\n","29/29 [==============================] - 0s 4ms/step - loss: 7.4062e-04 - accuracy: 1.0000\n","Epoch 161/200\n","29/29 [==============================] - 0s 5ms/step - loss: 5.0261e-04 - accuracy: 1.0000\n","Epoch 162/200\n","29/29 [==============================] - 0s 5ms/step - loss: 5.1980e-04 - accuracy: 1.0000\n","Epoch 163/200\n","29/29 [==============================] - 0s 4ms/step - loss: 4.5483e-04 - accuracy: 1.0000\n","Epoch 164/200\n","29/29 [==============================] - 0s 5ms/step - loss: 4.3775e-04 - accuracy: 1.0000\n","Epoch 165/200\n","29/29 [==============================] - 0s 4ms/step - loss: 4.2175e-04 - accuracy: 1.0000\n","Epoch 166/200\n","29/29 [==============================] - 0s 4ms/step - loss: 4.0971e-04 - accuracy: 1.0000\n","Epoch 167/200\n","29/29 [==============================] - 0s 4ms/step - loss: 4.2465e-04 - accuracy: 1.0000\n","Epoch 168/200\n","29/29 [==============================] - 0s 5ms/step - loss: 3.9325e-04 - accuracy: 1.0000\n","Epoch 169/200\n","29/29 [==============================] - 0s 4ms/step - loss: 3.8632e-04 - accuracy: 1.0000\n","Epoch 170/200\n","29/29 [==============================] - 0s 4ms/step - loss: 3.8223e-04 - accuracy: 1.0000\n","Epoch 171/200\n","29/29 [==============================] - 0s 4ms/step - loss: 4.3471e-04 - accuracy: 1.0000\n","Epoch 172/200\n","29/29 [==============================] - 0s 5ms/step - loss: 3.6933e-04 - accuracy: 1.0000\n","Epoch 173/200\n","29/29 [==============================] - 0s 5ms/step - loss: 3.9792e-04 - accuracy: 1.0000\n","Epoch 174/200\n","29/29 [==============================] - 0s 5ms/step - loss: 4.2687e-04 - accuracy: 1.0000\n","Epoch 175/200\n","29/29 [==============================] - 0s 5ms/step - loss: 3.4229e-04 - accuracy: 1.0000\n","Epoch 176/200\n","29/29 [==============================] - 0s 5ms/step - loss: 3.4354e-04 - accuracy: 1.0000\n","Epoch 177/200\n","29/29 [==============================] - 0s 5ms/step - loss: 3.6210e-04 - accuracy: 1.0000\n","Epoch 178/200\n","29/29 [==============================] - 0s 4ms/step - loss: 3.2767e-04 - accuracy: 1.0000\n","Epoch 179/200\n","29/29 [==============================] - 0s 5ms/step - loss: 3.2392e-04 - accuracy: 1.0000\n","Epoch 180/200\n","29/29 [==============================] - 0s 4ms/step - loss: 3.3967e-04 - accuracy: 1.0000\n","Epoch 181/200\n","29/29 [==============================] - 0s 4ms/step - loss: 4.0245e-04 - accuracy: 1.0000\n","Epoch 182/200\n","29/29 [==============================] - 0s 5ms/step - loss: 3.9379e-04 - accuracy: 1.0000\n","Epoch 183/200\n","29/29 [==============================] - 0s 4ms/step - loss: 4.1750e-04 - accuracy: 1.0000\n","Epoch 184/200\n","29/29 [==============================] - 0s 4ms/step - loss: 4.6182e-04 - accuracy: 1.0000\n","Epoch 185/200\n","29/29 [==============================] - 0s 4ms/step - loss: 3.7018e-04 - accuracy: 1.0000\n","Epoch 186/200\n","29/29 [==============================] - 0s 5ms/step - loss: 3.0216e-04 - accuracy: 1.0000\n","Epoch 187/200\n","29/29 [==============================] - 0s 4ms/step - loss: 3.0090e-04 - accuracy: 1.0000\n","Epoch 188/200\n","29/29 [==============================] - 0s 5ms/step - loss: 2.7919e-04 - accuracy: 1.0000\n","Epoch 189/200\n","29/29 [==============================] - 0s 5ms/step - loss: 2.6269e-04 - accuracy: 1.0000\n","Epoch 190/200\n","29/29 [==============================] - 0s 4ms/step - loss: 2.6324e-04 - accuracy: 1.0000\n","Epoch 191/200\n","29/29 [==============================] - 0s 4ms/step - loss: 2.6627e-04 - accuracy: 1.0000\n","Epoch 192/200\n","29/29 [==============================] - 0s 4ms/step - loss: 2.6079e-04 - accuracy: 1.0000\n","Epoch 193/200\n","29/29 [==============================] - 0s 4ms/step - loss: 2.4901e-04 - accuracy: 1.0000\n","Epoch 194/200\n","29/29 [==============================] - 0s 13ms/step - loss: 2.5148e-04 - accuracy: 1.0000\n","Epoch 195/200\n","29/29 [==============================] - 0s 11ms/step - loss: 2.3484e-04 - accuracy: 1.0000\n","Epoch 196/200\n","29/29 [==============================] - 0s 6ms/step - loss: 2.7685e-04 - accuracy: 1.0000\n","Epoch 197/200\n","29/29 [==============================] - 0s 4ms/step - loss: 2.4276e-04 - accuracy: 1.0000\n","Epoch 198/200\n","29/29 [==============================] - 0s 4ms/step - loss: 2.5337e-04 - accuracy: 1.0000\n","Epoch 199/200\n","29/29 [==============================] - 0s 4ms/step - loss: 2.3881e-04 - accuracy: 1.0000\n","Epoch 200/200\n","29/29 [==============================] - 0s 4ms/step - loss: 2.4051e-04 - accuracy: 1.0000\n"]}]},{"cell_type":"code","source":["score = model.evaluate(X_test, y_test)\n","print('Test Accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0c-V1dCdMU5t","executionInfo":{"status":"ok","timestamp":1659504824872,"user_tz":-540,"elapsed":697,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"outputId":"79c4192b-1805-4f3e-d6f5-8fb7affbc628"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 7ms/step - loss: 0.1613 - accuracy: 0.9365\n","Test Accuracy: 0.9365079402923584\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model"],"metadata":{"id":"uGoDXZCQOXMr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save('/data/model/my_model.hdf5')"],"metadata":{"id":"tpTriJeBOc8j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del model"],"metadata":{"id":"X2J2OadxPWTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = load_model('/data/model/my_model.hdf5')"],"metadata":{"id":"3gZnK7OQPZKF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test,y_test)\n","print('Test Accuracy: ', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvDY_ISyPfJY","executionInfo":{"status":"ok","timestamp":1659505626204,"user_tz":-540,"elapsed":437,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"outputId":"cd83c85b-fbeb-4fdc-81bc-b45249f0886a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 10ms/step - loss: 0.1613 - accuracy: 0.9365\n","Test Accuracy:  0.9365079402923584\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import KFold"],"metadata":{"id":"kzwTBDi9PmBg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k = 5\n","kfold = KFold(n_splits = k, shuffle = True)\n","acc_score = []"],"metadata":{"id":"-SGaDJaoP16a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for train_index, test_index in kfold.split(X):\n","  X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n","  y_train, y_test = y.iloc[train_index], y.iloc[test_index]"],"metadata":{"id":"U9mhMeP4P_5U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy = model.evaluate(X_test,y_test)[1]\n","acc_score = score.append(accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GwYSgM2hUtYr","executionInfo":{"status":"ok","timestamp":1659507008002,"user_tz":-540,"elapsed":4,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"outputId":"3b7ad083-9b97-447e-ce83-806c95d23dd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9756\n"]}]},{"cell_type":"code","source":["def model_fn():\n","  model = Sequential()\n","  model.add(Dense(24, input_dim = 60, activation = 'relu'))\n","  model.add(Dense(10, activation = 'relu'))\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  return model"],"metadata":{"id":"Fd_7mMF1VNqZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for train_index, test_index in kfold.split(X):\n","  X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n","  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","  model = model_fn()\n","  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","  history = model.fit(X_train, y_train, epochs = 200, batch_size = 10, verbose = 0)\n","  accuracy = model.evaluate(X_test,y_test)[1]\n","  acc_score.append(accuracy)\n","  avg_score = sum(acc_score)/k\n","  print('정확도 {} 정확도 평균 {} ' % (acc_score, avg_score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301},"id":"Lowol0KNVeal","executionInfo":{"status":"error","timestamp":1659507573116,"user_tz":-540,"elapsed":5965,"user":{"displayName":"꼬꾸마시","userId":"03618166330528026934"}},"outputId":"9200f165-573f-4b8d-bbf7-8e30f4ca0f74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5a088baf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 6ms/step - loss: 0.6528 - accuracy: 0.8333\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-dc0b5f694d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0macc_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mavg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'정확도 {} 정확도 평균 {} '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"]}]}]}